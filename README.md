# PredicciÃ³n de situaciones de trata de personas (2020â€“2023) â€” README

> **Proyecto de Aprendizaje AutomÃ¡tico** Â· Tecnicatura en Ciencia de Datos e IA  
> **Autora:** Ana MarÃ­a FernÃ¡ndez Â· **Ãmbito:** Oficina de Rescate y AcompaÃ±amiento (AR)  
> **Enfoque territorial:** Tierra del Fuego (transferencia del modelo)
> 
## 1) Objetivo
> ğŸ“„ **Informe completo (PDF)**: [Ver en Google Drive](https://drive.google.com/file/d/1AvKjNq2TPsjG6Hjy8Ap9MwXs9K5kZrEF/view?usp=sharing) Â· [Descargar](https://drive.google.com/uc?export=download&id=1AvKjNq2TPsjG6Hjy8Ap9MwXs9K5kZrEF)

**Clasificar** si una intervenciÃ³n de la Oficina de Rescate (ene-2020 a ago-2023) corresponde a **trata (1)** o **no trata (0)**.

- **Objetivo general:** construir un clasificador binario robusto y transferible a contextos de baja frecuencia (Tierra del Fuego).
- **Objetivos especÃ­ficos:**
  1. EDA y preparaciÃ³n (valores faltantes, desbalance, patrones regionales).
  2. Entrenar y comparar modelos supervisados priorizando **recall**.
  3. **Transfer learning local:** evaluar el mejor modelo nacional sobre los **27** casos de TDF.

> ğŸ“ **Carpeta del proyecto (Drive)**:  
> [Abrir en Google Drive](https://drive.google.com/drive/folders/1Pi_5rFwRCzmmJpSQl1gV6k_Ke6B7OvzF?usp=drive_link)

## 2) Datos
- **Fuente:** `oficina-rescate-orientaciones-202001-202308.csv`
- **Registros:** **7.853** (Argentina).  
  Confirmadas como trata: **4.241** (~54%).  
  **Tierra del Fuego:** 27 intervenciones, 20 casos de trata.
- **Target:** `es_trata` (1/0)
- **Features relevantes (ejemplos):** `es_anonima`, `origen`, `subtema`, `provincia`, `via_ingreso`, `consultante_genero`, `consultante_edad_aparente`.

## 3) MetodologÃ­a
- **Preprocesamiento:** imputaciÃ³n (KNNImputer), one-hot para categÃ³ricas, standard scaling para numÃ©ricas, split 80/20 estratificado.
- **Modelos evaluados:** RegresiÃ³n LogÃ­stica (baseline interpretable), Ãrbol de DecisiÃ³n, Random Forest y **HistGradientBoostingClassifier** (como baseline alternativo).
- **ValidaciÃ³n:** CV estratificada (k=5). **OptimizaciÃ³n** por Grid/Random Search enfocada en **recall**.
- **SelecciÃ³n y umbral:** curva PR y ajuste de umbral para maximizar recall con costo controlado de FP.

## 4) Resultados (resumen)
- **Mejor pipeline:** `Tuned-LogisticRegression` con **umbral = 0.328** (optimizado por PR para recall temprano).
- **Baseline alternativo:** `HistGradientBoostingClassifier` con **F1 = 0.304** (referencia).
- **Archivos de respaldo de nulos:**  
  - `results/nulos_antes.csv`  
  - `results/nulos_despues.csv`
- **MÃ©tricas detalladas:** ver `results/metrics_*.csv` y grÃ¡ficos en `figs/` (PR, ROC, matrices 0.5 vs Ã³ptimo, calibration).

> âš ï¸ *Nota*: Las mÃ©tricas finales exactas (precision, recall, F1, ROC-AUC) y las tablas por umbral deben tomarse **tal cual** del notebook del proyecto y ya estÃ¡n exportadas en `results/`. Este README **respeta** nombres, umbrales y valores clave indicados por la autora.


## 5) Transferencia a Tierra del Fuego
- Se aplica el mejor clasificador nacional (`Tuned-LogisticRegression @ thr=0.328`) al subconjunto TDF (27 casos).
- Se reporta desempeÃ±o local (confusiÃ³n, recall, PPV) y se revisan errores FN/FP para **ajustes de umbral** y **criterios operativos**.

## 6) Estructura del repositorio (Cookiecutter Data Science)
```
â”œâ”€ data/
â”‚  â”œâ”€ raw/     # CSV original
â”‚  â”œâ”€ interim/ # limpiezas parciales
â”‚  â””â”€ processed/ # dataset canÃ³nico
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda_preprocesamiento.ipynb
â”‚  â”œâ”€ 02_modelado_cv_tuning.ipynb
â”‚  â”œâ”€ 03_umbral_pr_y_diagnosticos.ipynb
â”‚  â””â”€ 04_transfer_tdf.ipynb
â”œâ”€ results/
â”‚  â”œâ”€ nulos_antes.csv
â”‚  â”œâ”€ nulos_despues.csv
â”‚  â”œâ”€ metrics_cv.csv
â”‚  â””â”€ metrics_test_thr0328.csv
â”œâ”€ figs/
â”‚  â”œâ”€ pr_curve_thr0328.png
â”‚  â”œâ”€ roc_curve.png
â”‚  â”œâ”€ confusion_050.png
â”‚  â””â”€ confusion_thr0328.png
â””â”€ README.md
```

## 7) Consideraciones Ã©ticas y privacidad
- AnonimizaciÃ³n estricta, no publicar PII. Uso educativo con fines de mejora operativa.

## 8) Entorno
- Python 3.10 Â· pandas 1.5 Â· numpy 1.23 Â· scikit-learn 1.2 Â· imbalanced-learn Â· shap Â· seaborn

## 9) Citas y marco de clase
- Clase 4: RegresiÃ³n lineal y logÃ­stica; Clase 5: KNN y Ãrboles; Clase 6: SVM/SGD; Clase 8: Clustering (material teÃ³rico y prÃ¡cticas).

## 10) BitÃ¡cora del proceso del proyecto

Este proyecto no naciÃ³ â€œordenadoâ€. EmpezÃ³ como casi todos: con ilusiÃ³n, con prisa y con algunas torpezas que, con el tiempo, se volvieron aprendizaje. La primera piedra fue tan simple como cruel: las rutas. Guardaba grÃ¡ficos y tablas como si las carpetas existieran por arte de magia; no existÃ­an. Ese primer FileNotFoundError me obligÃ³ a crear figs/ y results/, a adoptar rutas relativas y a entender que la prolijidad del directorio tambiÃ©n es ciencia de datos.

DespuÃ©s vino la fase de modelado. AhÃ­ aprendÃ­ que un buen pipeline es mÃ¡s que un modelo que â€œandaâ€. EncerrÃ© imputaciÃ³n, codificaciÃ³n y escalado dentro del Pipeline, hice CV estratificada y prioricÃ© recall. La decisiÃ³n de ajustar el umbral 0.328 no fue capricho: comparÃ© contra 0.5, mirÃ© PR y aceptÃ© mÃ¡s FP para ganar detecciÃ³n temprana. Hubo celdas rebeldes (la 12, la 16, la 21â€¦) que mostraron que renombrar una variable en una celda rompe tres mÃ¡s adelante. TomÃ© nota: nombres estables, comentarios claros y resultados versionados en results/.

La parte GitHub fue otra novela. El editor web me tirÃ³ el aviso de â€œmixed line endingsâ€ y terminÃ© editando en github.dev (la tecla .) para forzar LF. Cuando subÃ­ el PDF, el visor de GitHub no lo pudo abrir: por orden de reglas en .gitattributes, el PDF se tratÃ³ como texto y quedÃ³ inutilizable. CorregÃ­ eso con -text para binarios y renormalicÃ© el repoâ€¦ pero, aun asÃ­, hoy el informe no se visualiza en GitHub. Por ese motivo, lo voy a publicar como enlace a Google Drive dentro del README, hasta estabilizar la visualizaciÃ³n en el repo.

Con los grÃ¡ficos pasÃ³ algo parecido: en la vista normal de GitHub no se ven (solo puedo verlos entrando a GitHubDev). Mientras persista esa limitaciÃ³n, el README no puede mostrarlos embebidos; voy a dejar las referencias a los archivos en figs/ y, cuando corresponda, los enlaces a Drive como respaldo.

Al final, la seguidilla de problemas terminÃ³ siendo un plan de estudios paralelo: ordenar carpetas, blindar el preprocesamiento, justificar el umbral por objetivo operativo, cuidar los finales de lÃ­nea y documentar limitaciones tÃ©cnicas (PDF por Drive y figuras visibles solo en GitHubDev por ahora). Si este README se ve bien, si las mÃ©tricas reproducen el 0.328 elegido y si el flujo estÃ¡ claro, es porque cada tropiezo dejÃ³ una marca: una carpeta creada a tiempo, una regla en .gitattributes, un enlace a Drive, una nota sobre visualizaciÃ³n. AsÃ­, de a poco, el proyecto empezÃ³ a parecerse al proyecto que querÃ­a hacer.
---

Â© 2025 Ana MarÃ­a FernÃ¡ndez â€” Tecnicatura en Ciencia de Datos e IA
