# PredicciÃ³n de situaciones de trata de personas (2020â€“2024)

> **Proyecto de Aprendizaje AutomÃ¡tico** Â· Tecnicatura en Ciencia de Datos e IA  
> **Autora:** Ana MarÃ­a FernÃ¡ndez Â· **Ãmbito:** Oficina de Rescate y AcompaÃ±amiento (AR)  
> **Enfoque territorial:** Tierra del Fuego (transferencia del modelo)

## 1) Objetivo
**Clasificar** si una intervenciÃ³n de la Oficina de Rescate (ene-2020 a oct-2024) corresponde a **trata (1)** o **no trata (0)**.

- **Objetivo general:** construir un clasificador binario robusto y transferible a contextos de baja frecuencia (Tierra del Fuego).
- **Objetivos especÃ­ficos:**
  1. EDA y preparaciÃ³n (valores faltantes, balance, patrones regionales).
  2. Entrenar y comparar modelos supervisados priorizando **recall**.
  3. **Transferencia local (TDF):** evaluar el mejor modelo nacional sobre el subconjunto local (n pequeÃ±o) y ajustar umbral si es necesario.

ğŸ“„ **Informe completo (PDF):** [Ver](https://drive.google.com/file/d/1KOsoBH0DmTL9VTpilG6K0Wa1Wn1yGD0I/view?usp=drive_link) Â· [Descargar el informe (PDF)](https://drive.google.com/uc?export=download&id=1KOsoBH0DmTL9VTpilG6K0Wa1Wn1yGD0I)
ğŸ“ **Carpeta del proyecto (Drive):** [Abrir](https://drive.google.com/drive/folders/1Pi_5rFwRCzmmJpSQl1gV6k_Ke6B7OvzF?usp=drive_link)

---

## 2) Datos
### Fuente y alcance del dataset
- **Origen**: Oficina de Rescate y AcompaÃ±amiento (AR), Argentina.
- **Cobertura temporal**: ene-2020 a dic-2024 (corte incluido).
- **Fecha de adquisiciÃ³n**: dd/mm/aaaa.
- **Uso y estado**: Con fines educativos; datos normalizados y **anonimizados** (sin PII).
- **Accesos**:
  - CSV procesado (canÃ³nico) â€” *si el repo no lo puede alojar por tamaÃ±o/privacidad*: [Descargar desde Drive](https://drive.google.com/file/d/1_ttFnO6qTHTiBnFyFbd5pzR4SB0cjPgc/view?usp=sharing)
  - Estructura de carpetas del proyecto en este repositorio (`data/raw`, `data/processed`, `results`, `figs`).

### DescripciÃ³n del dataset (resumen)
- **Instancias**: 7.848
- **CaracterÃ­sticas**: 26 columnas (ver diccionario)
- **Target**: `es_trata` (1/0) â€” balance: 1=54% (4241), 0=46% (3607)
- **Tipos y nulos**: ver `results/nulos_antes.csv` y `results/nulos_despues.csv`  
  (incluyen conteos, % nulos y dtype por columna).
- **Transformaciones principales**:
  - NormalizaciÃ³n de strings y categorÃ­as (provincias/localidades/nacionalidad).
  - DerivaciÃ³n temporal (`anio`, `mes`, `trimestre`, `dia_semana`, `es_fin_semana`, `mes_sin`, `mes_cos`).
  - ConstrucciÃ³n robusta de `es_trata` (reglas auditadas).
  - EliminaciÃ³n de `hora_ingreso` por estar vacÃ­a.

### Diccionario de datos (extracto)
| columna                      | tipo     | descripciÃ³n breve                              | % nulos | # Ãºnicos |
|-----------------------------|----------|-----------------------------------------------|---------|---------|
| `es_trata`                  | int (0/1)| Etiqueta binaria (objetivo)                   | 0%      | 2       |
| `consultante_provincia`     | string   | Provincia normalizada (INDEC)                 | ~40%    | ~25     |
| `consultante_localidad`     | string   | Localidad normalizada                         | ~81%    | ~351    |
| `consultante_nacionalidad`  | string   | Nacionalidad normalizada                      | ~76%    | ~18     |
| `consultante_edad_aparente` | float    | Edad aparente                                 | ~15%    | ~88     |
| `anio` `mes` `trimestre`    | int      | Derivadas temporales                          | â€”       | â€”       |
| `mes_sin` `mes_cos`         | float    | Componentes cÃ­clicos del mes                  | â€”       | â€”       |
> El detalle completo estÃ¡ en `results/nulos_*.csv`.

---

## 3) MetodologÃ­a
- **ValidaciÃ³n:** split **temporal** (train/valid/test por fechas) sin fuga; **backtesting rolling-origin** mensual (2020-07â†’2024-12).
- **OptimizaciÃ³n de umbral:** por **curva Precisionâ€“Recall** con restricciÃ³n **recall â‰¥ 0.80**.
- **CalibraciÃ³n de probabilidades:** IsotÃ³nica/Platt; evaluaciÃ³n por **Brier** y curva de calibraciÃ³n.
- **Modelos evaluados:** Logistic Regression (base), **Logistic Regression + interacciones** (temporadaÃ—anonimato, provinciaÃ—anonimato, nacionalidadÃ—temporada) y **HistGradientBoosting** (con/sin calibraciÃ³n).
- **Reproducibilidad:** pipelines y umbrales persistidos; semillas fijas.

---

## 4) Resultados (resumen)
- **Modelo seleccionado (operativo):** **Logistic Regression + interacciones** con **umbral = 0.345** (PR con recall â‰¥ 0.80).  
  **Test:** **Precision 0.563 Â· Recall 0.972 Â· F1 0.713 Â· ROC-AUC 0.623**.
- **Alternativa si se prioriza F1/ROC:** **HistGradientBoosting calibrado** con **umbral = 0.396**.  
  **Test:** **Precision 0.562 Â· Recall 0.958 Â· F1 0.708 Â· ROC-AUC 0.659 Â· AP 0.685**  
  (Brier **0.243 â†’ 0.234** tras calibraciÃ³n).
- **Modelo base (referencia):** **Tuned-LogisticRegression @ thr = 0.328**.  
  **Test:** **Precision 0.559 Â· Recall 0.951 Â· F1 0.704 Â· AP 0.667 Â· ROC-AUC 0.628**.
- **Backtesting temporal (promedios):** **Precision 0.647 Â· Recall 0.686 Â· F1 0.651**.

**Archivos clave exportados**
- MÃ©tricas/tablas:  
  `results/modelos_metricas.csv`, `results/hp_search_resumen.csv`, `results/hp_best_holdout_metrics.csv`,  
  `results/best_metrics_Tuned-LogisticRegression_c16.csv`,  
  `results/best_threshold_Tuned-LogisticRegression_c16.json`,  
  `results/classification_report_Tuned-LogisticRegression_opt_c16.txt`
- Figuras (ejemplos):  
  `figs/pr_Tuned-LogisticRegression_c16.png`, `figs/pr_HGB.png`, `figs/roc_HGB.png`,  
  `figs/cm_Tuned-LogisticRegression_050_c16.png`, `figs/cm_Tuned-LogisticRegression_opt_c16.png`

---

## 5) Transferencia a Tierra del Fuego
- EvaluaciÃ³n del mejor clasificador nacional sobre **TDF** (muestra chica).  
- Con **LogReg + interacciones** y **mismo umbral (0.345)** en corrida especÃ­fica (**n=30**, **positivos=22**):  
  **Precision 0.733 Â· Recall 1.00 Â· F1 0.846**.  
  *Cautela por bajo N; monitoreo mensual y recalibraciÃ³n si cambia la casuÃ­stica.*

---

## 6) Estructura del repositorio
```
â”œâ”€ data/
â”‚  â”œâ”€ raw/         # CSV original
â”‚  â”œâ”€ interim/     # limpiezas parciales
â”‚  â””â”€ processed/   # dataset canÃ³nico
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda_preprocesamiento.ipynb
â”‚  â”œâ”€ 02_modelado_cv_tuning.ipynb
â”‚  â”œâ”€ 03_umbral_pr_y_diagnosticos.ipynb
â”‚  â””â”€ 04_transfer_tdf.ipynb
â”œâ”€ results/
â”‚  â”œâ”€ nulos_antes.csv
â”‚  â”œâ”€ nulos_despues.csv
â”‚  â”œâ”€ modelos_metricas.csv
â”‚  â”œâ”€ hp_search_resumen.csv
â”‚  â”œâ”€ hp_best_holdout_metrics.csv
â”‚  â”œâ”€ best_metrics_Tuned-LogisticRegression_c16.csv
â”‚  â”œâ”€ best_threshold_Tuned-LogisticRegression_c16.json
â”‚  â””â”€ classification_report_Tuned-LogisticRegression_opt_c16.txt
â”œâ”€ figs/
â”‚  â”œâ”€ pr_Tuned-LogisticRegression_c16.png
â”‚  â”œâ”€ pr_HGB.png
â”‚  â”œâ”€ roc_HGB.png
â”‚  â”œâ”€ cm_Tuned-LogisticRegression_050_c16.png
â”‚  â””â”€ cm_Tuned-LogisticRegression_opt_c16.png
â””â”€ README.md
```

## 7) Consideraciones Ã©ticas y privacidad
- AnonimizaciÃ³n estricta, no publicar PII. Uso educativo con fines de mejora operativa.

## 8) Entorno
- Python 3.10 Â· pandas 1.5 Â· numpy 1.23 Â· scikit-learn 1.2 Â· imbalanced-learn Â· shap Â· seaborn

## 9) Citas y marco de clase
- Clase 4: RegresiÃ³n lineal y logÃ­stica; Clase 5: KNN y Ãrboles; Clase 6: SVM/SGD; Clase 8: Clustering (material teÃ³rico y prÃ¡cticas).

## 10) BitÃ¡cora del proceso del proyecto

Este proyecto no naciÃ³ â€œordenadoâ€. EmpezÃ³ como casi todos: con ilusiÃ³n, con prisa y con algunas torpezas que, con el tiempo, se volvieron aprendizaje. La primera piedra fue tan simple como cruel: las rutas. Guardaba grÃ¡ficos y tablas como si las carpetas existieran por arte de magia; no existÃ­an. Ese primer FileNotFoundError me obligÃ³ a crear figs/ y results/, a adoptar rutas relativas y a entender que la prolijidad del directorio tambiÃ©n es ciencia de datos.

DespuÃ©s vino la fase de modelado. AhÃ­ aprendÃ­ que un buen pipeline es mÃ¡s que un modelo que â€œandaâ€. EncerrÃ© imputaciÃ³n, codificaciÃ³n y escalado dentro del Pipeline, hice CV estratificada y prioricÃ© recall. La decisiÃ³n de ajustar el umbral 0.328 no fue capricho: comparÃ© contra 0.5, mirÃ© PR y aceptÃ© mÃ¡s FP para ganar detecciÃ³n temprana. Hubo celdas rebeldes (la 12, la 16, la 21â€¦) que mostraron que renombrar una variable en una celda rompe tres mÃ¡s adelante. TomÃ© nota: nombres estables, comentarios claros y resultados versionados en results/.

La parte GitHub fue otra novela. El editor web me tirÃ³ el aviso de â€œmixed line endingsâ€ y terminÃ© editando en github.dev (la tecla .) para forzar LF. Cuando subÃ­ el PDF, el visor de GitHub no lo pudo abrir: por orden de reglas en .gitattributes, el PDF se tratÃ³ como texto y quedÃ³ inutilizable. CorregÃ­ eso con -text para binarios y renormalicÃ© el repoâ€¦ pero, aun asÃ­, hoy el informe no se visualiza en GitHub. Por ese motivo, lo voy a publicar como enlace a Google Drive dentro del README, hasta estabilizar la visualizaciÃ³n en el repo.

Con los grÃ¡ficos pasÃ³ algo parecido: en la vista normal de GitHub no se ven (solo puedo verlos entrando a GitHubDev). Mientras persista esa limitaciÃ³n, el README no puede mostrarlos embebidos; voy a dejar las referencias a los archivos en figs/ y, cuando corresponda, los enlaces a Drive como respaldo.

Al final, la seguidilla de problemas terminÃ³ siendo un plan de estudios paralelo: ordenar carpetas, blindar el preprocesamiento, justificar el umbral por objetivo operativo, cuidar los finales de lÃ­nea y documentar limitaciones tÃ©cnicas (PDF por Drive y figuras visibles solo en GitHubDev por ahora). Si este README se ve bien, si las mÃ©tricas reproducen el 0.328 elegido y si el flujo estÃ¡ claro, es porque cada tropiezo dejÃ³ una marca: una carpeta creada a tiempo, una regla en .gitattributes, un enlace a Drive, una nota sobre visualizaciÃ³n. AsÃ­, de a poco, el proyecto empezÃ³ a parecerse al proyecto que querÃ­a hacer.
---

Â© 2025 Ana MarÃ­a FernÃ¡ndez â€” Tecnicatura en Ciencia de Datos e IA
